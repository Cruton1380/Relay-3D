# Relay Network AI Agent Configuration
# Copy this file to .env and fill in your actual values

# ===== LLM CONFIGURATION =====
# Primary LLM source: local | cloud | hybrid
RELAY_USE_LOCAL_LLM=false

# Default cloud provider when using cloud LLMs
RELAY_CLOUD_PROVIDER=openai

# Local LLM Configuration
RELAY_LOCAL_LLM_ENDPOINT=http://localhost:11434
RELAY_LOCAL_LLM_MODEL=llama3:8b
RELAY_LOCAL_PROVIDER=ollama

# ===== SYSTEM API KEYS (Optional - for system-wide access) =====
# OpenAI Configuration (Required for Navigator agent)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_openai_org_id_optional
OPENAI_MODEL=gpt-4o

# Anthropic Configuration (Required for Architect agent)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google AI Configuration
GOOGLE_API_KEY=your-google-ai-api-key-here
GOOGLE_MODEL=gemini-1.5-pro

# Mistral Configuration
MISTRAL_API_KEY=your-mistral-api-key-here
MISTRAL_MODEL=mistral-large-latest

# Cohere Configuration
COHERE_API_KEY=your-cohere-api-key-here
COHERE_MODEL=command-r-plus

# Together AI Configuration
TOGETHER_API_KEY=your-together-api-key-here

# DeepSeek Configuration (Optional alternative for Architect)
DEEPSEEK_API_KEY=your_deepseek_api_key_optional

# ===== USER API KEYS (User-provided, encrypted storage) =====
# Users can provide their own API keys via CLI or UI
# These are encrypted and stored per-user
USER_OPENAI_API_KEY=
USER_ANTHROPIC_API_KEY=
USER_GOOGLE_API_KEY=
USER_MISTRAL_API_KEY=

# ===== AGENT CONFIGURATION =====
# Default models for each agent type
RELAY_NAVIGATOR_MODEL=gpt-4o
RELAY_ARCHITECT_MODEL=claude-3-5-sonnet-20241022

# Agent behavior settings
RELAY_AGENT_MAX_TOKENS=4096
RELAY_AGENT_TEMPERATURE=0.7
RELAY_ENABLE_AGENT_MEMORY=true

# ===== SECURITY & PRIVACY =====
# Encryption key for user credentials (generate a strong random string)
RELAY_ENCRYPTION_KEY=generate_32_character_random_string

# Privacy and Security Settings
PRIVACY_LEVEL=high
MEMORY_ENCRYPTION_KEY=generate_32_character_random_string
ALLOW_MEMORY_STORAGE=true
ENABLE_PROMPT_SCRUBBING=true

# Privacy settings
RELAY_STRIP_USER_DATA=true
RELAY_LOG_PROMPTS=false
RELAY_ENABLE_AUDIT_TRAIL=true

# Model availability checking
RELAY_HEALTH_CHECK_INTERVAL=300000
RELAY_AUTO_FALLBACK=true

# ===== DEVELOPMENT & DEBUGGING =====
# System Configuration
LOG_LEVEL=info
DEBUG_MODE=false
RELAY_ENABLE_AGENT_DEBUG=false

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
RESPONSE_TIMEOUT=30000
ENABLE_RESPONSE_CACHING=true
CACHE_TIMEOUT=3600
ENABLE_BATCH_PROCESSING=true

# Performance monitoring
RELAY_ENABLE_PERFORMANCE_MONITORING=true
RELAY_METRICS_ENDPOINT=http://localhost:9090

# ===== COLLABORATION & FALLBACK =====
# Collaboration Settings
MAX_COLLABORATION_ITERATIONS=5
ENABLE_DEADLOCK_DETECTION=true
AUTO_ESCALATE_DEADLOCKS=true

# Model Fallback Configuration
ENABLE_MODEL_FALLBACK=true
FALLBACK_RETRY_COUNT=3
EXPONENTIAL_BACKOFF=true

# ===== LOCAL INDEX CONFIGURATION =====
# Local Index Configuration
INDEX_ENABLED=true
INDEX_PATH=./src
INDEX_FILE_EXTENSIONS=.js,.mjs,.ts,.tsx,.md,.json
INDEX_EXCLUDE_PATTERNS=node_modules,.git,dist,build

# ===== DEVELOPMENT & TESTING =====
# Development and Testing
MOCK_LLM_RESPONSES=false
SKIP_API_CALLS=false
TEST_MODE=false

# ===== NETWORK CONFIGURATION =====
# Relay Network specific settings
RELAY_NODE_ID=
RELAY_PRIVATE_KEY=
RELAY_PUBLIC_KEY=
RELAY_BOOTSTRAP_PEERS=

# Database configuration
DATABASE_URL=sqlite:./data/relay.db

# ===== PRODUCTION SETTINGS =====
# Production Settings (uncomment for production)
# NODE_ENV=production
# RATE_LIMIT_ENABLED=true
# AUDIT_LOGGING=true
# METRICS_COLLECTION=true

# ===== EXPERIMENTAL FEATURES =====
# Future federated inference support
RELAY_ENABLE_FEDERATED_INFERENCE=false
RELAY_PEER_INFERENCE_ENABLED=false
RELAY_COMMUNITY_NODES_ENABLED=false

# Model fine-tuning and customization
RELAY_ENABLE_MODEL_FINE_TUNING=false
RELAY_CUSTOM_MODEL_PATH=./models/custom/

# ===== CLI FLAGS REFERENCE =====
# Available CLI flags for LLM configuration:
#   --llm-source=openai | anthropic | local | ollama:llama3
#   --cloud-provider=openai | anthropic | google | mistral
#   --use-local
#   --navigator-model=model-name
#   --architect-model=model-name
#   --enable-user-keys
#   --health-check
