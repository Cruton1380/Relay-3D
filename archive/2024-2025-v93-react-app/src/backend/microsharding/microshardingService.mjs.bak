/**
 * @fileoverview Microsharding Service - Provides distributed data sharding and retrieval.
 * This service implements data sharding, redundancy, and distributed storage/retrieval.
 * It uses a combination of erasure coding and Merkle trees for data integrity.
 * 
 * ARCHITECTURE OVERVIEW:
 * - Data is split into fixed-size shards
 * - Redundant shards are generated using erasure coding (simplified XOR in this implementation)
 * - Merkle trees provide integrity verification for all shards
 * - Shards are distributed across network peers with configurable redundancy
 * - Reconstruction can occur even with some missing shards
 */
import crypto from 'crypto';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import logger from '../utils/logging/logger.mjs';
import peerManager from '../network/peerManager.mjs';
import { eventBus } from '../services/eventBus.mjs';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Create logger
const shardLogger = logger.child({ module: 'microsharding' });

// Shard configuration
const DEFAULT_SHARD_SIZE = 256 * 1024; // 256KB
const DEFAULT_REDUNDANCY = 3;          // Store 3 copies of each shard
const MERKLE_BRANCH_FACTOR = 16;       // Merkle tree branching factor
const SHARD_TIMEOUT = 30000;           // 30 seconds timeout for shard operations
const MAX_RETRY_COUNT = 3;             // Maximum number of retries for shard operations

// Path for local shard storage
const SHARDS_DIR = path.join(process.env.DATA_DIR || './data', 'shards');

// Cache for metadata lookups
const metadataCache = new Map();

/**
 * Ensure shards directory exists
 * @returns {Promise<void>}
 */
async function ensureShardsDir() {
  try {
    await fs.mkdir(SHARDS_DIR, { recursive: true });
    shardLogger.info('Shards directory created or verified', { path: SHARDS_DIR });
  } catch (error) {
    shardLogger.error('Failed to create shards directory', { 
      path: SHARDS_DIR, 
      error: error.message 
    });
    throw new Error(`Failed to create shards directory: ${error.message}`);
  }
}

/**
 * Shard data into multiple chunks
 * @param {Buffer} data - Data to shard
 * @param {number} shardSize - Size of each shard in bytes
 * @returns {Array<Buffer>} Array of data shards
 */
function shardData(data, shardSize = DEFAULT_SHARD_SIZE) {
  if (!Buffer.isBuffer(data)) {
    data = Buffer.from(data);
  }
  
  const shards = [];
  const totalShards = Math.ceil(data.length / shardSize);
  
  shardLogger.debug('Sharding data', { 
    dataSize: data.length, 
    shardSize, 
    totalShards 
  });
  
  for (let i = 0; i < totalShards; i++) {
    const start = i * shardSize;
    const end = Math.min(start + shardSize, data.length);
    const shardData = data.slice(start, end);
    shards.push(shardData);
  }
  
  return shards;
}

/**
 * Generate erasure coding data for redundancy
 * @param {Array<Buffer>} dataShards - Original data shards
 * @param {number} redundancy - Number of redundant shards to create
 * @returns {Array<Buffer>} Redundant shards
 */
function generateRedundantShards(dataShards, redundancy = DEFAULT_REDUNDANCY) {
  // In a production system, this would use Reed-Solomon coding or a similar algorithm
  // This implementation creates parity shards using XOR for demonstration
  
  const redundantShards = [];
  
  for (let i = 0; i < redundancy; i++) {
    // For each redundancy level, create a parity shard
    const parityBuffer = Buffer.alloc(dataShards[0].length);
    
    // XOR all data shards together
    for (const shard of dataShards) {
      for (let j = 0; j < shard.length; j++) {
        parityBuffer[j] ^= shard[j];
      }
    }
    
    // Add some variation to each parity shard
    const nonce = crypto.randomBytes(4);
    for (let j = 0; j < 4 && j < parityBuffer.length; j++) {
      parityBuffer[j] ^= nonce[j];
    }
    
    redundantShards.push(parityBuffer);
  }
  
  shardLogger.debug('Generated redundant shards', { 
    dataShards: dataShards.length, 
    redundantShards: redundantShards.length 
  });
  
  return redundantShards;
}

/**
 * Generate a Merkle tree from shards for verification
 * @param {Array<Buffer>} shards - All shards (data + redundant)
 * @returns {Object} Merkle tree and root hash
 */
function generateMerkleTree(shards) {
  // Hash all shards individually
  const leaves = shards.map(shard => {
    const hash = crypto.createHash('sha256');
    hash.update(shard);
    return hash.digest();
  });
  
  // Build the Merkle tree
  let level = leaves;
  const tree = [level];
  
  while (level.length > 1) {
    const nextLevel = [];
    
    for (let i = 0; i < level.length; i += MERKLE_BRANCH_FACTOR) {
      const nodes = level.slice(i, i + MERKLE_BRANCH_FACTOR);
      const combinedHash = crypto.createHash('sha256');
      
      for (const node of nodes) {
        combinedHash.update(node);
      }
      
      nextLevel.push(combinedHash.digest());
    }
    
    level = nextLevel;
    tree.push(level);
  }
  
  const rootHash = level[0].toString('hex');
  
  shardLogger.debug('Generated Merkle tree', { 
    leaves: leaves.length, 
    levels: tree.length,
    rootHash: rootHash.substring(0, 10) + '...'
  });
  
  return {
    tree,
    rootHash
  };
}

/**
 * Create a unique shard ID
 * @param {Buffer} shardData - Shard data
 * @param {number} shardIndex - Index of the shard
 * @param {string} dataId - ID of the original data
 * @returns {string} Unique shard ID
 */
function createShardId(shardData, shardIndex, dataId) {
  const hash = crypto.createHash('sha256');
  hash.update(shardData);
  hash.update(Buffer.from(shardIndex.toString()));
  hash.update(Buffer.from(dataId));
  return hash.digest('hex');
}

/**
 * Create a new shard object with metadata
 * @param {Buffer} data - Shard data
 * @param {number} index - Shard index
 * @param {string} dataId - ID of the original data
 * @param {boolean} isRedundant - Whether this is a redundant shard
 * @returns {Object} Shard information
 */
function createShard(data, index, dataId, isRedundant = false) {
  if (!Buffer.isBuffer(data)) {
    data = Buffer.from(data);
  }
  
  const shardId = createShardId(data, index, dataId);
  
  return {
    id: shardId,
    data,
    index,
    size: data.length,
    isRedundant,
    dataId,
    createdAt: Date.now()
  };
}

/**
 * Store a shard locally
 * @param {string} shardId - Unique shard identifier
 * @param {Buffer} shardData - Shard data
 * @returns {Promise<boolean>} Success status
 */
async function storeShardLocally(shardId, shardData) {
  try {
    await ensureShardsDir();
    const shardPath = path.join(SHARDS_DIR, `${shardId}.shard`);
    await fs.writeFile(shardPath, shardData);
    
    shardLogger.debug('Shard stored locally', { 
      shardId: shardId.substring(0, 10) + '...',
      size: shardData.length
    });
    
    return true;
  } catch (error) {
    shardLogger.error('Failed to store shard locally', { 
      shardId: shardId.substring(0, 10) + '...',
      error: error.message
    });
    
    throw new Error(`Failed to store shard locally: ${error.message}`);
  }
}

/**
 * Retrieve a shard from local storage
 * @param {string} shardId - Shard identifier
 * @returns {Promise<Buffer|null>} Shard data or null if not found
 */
async function getShardLocally(shardId) {
  try {
    const shardPath = path.join(SHARDS_DIR, `${shardId}.shard`);
    const shardData = await fs.readFile(shardPath);
    
    shardLogger.debug('Retrieved shard locally', { 
      shardId: shardId.substring(0, 10) + '...',
      size: shardData.length
    });
    
    return shardData;
  } catch (error) {
    if (error.code === 'ENOENT') {
      shardLogger.debug('Shard not found locally', { 
        shardId: shardId.substring(0, 10) + '...' 
      });
      return null;
    }
    
    shardLogger.error('Failed to retrieve shard locally', { 
      shardId: shardId.substring(0, 10) + '...',
      error: error.message
    });
    
    throw new Error(`Failed to retrieve shard: ${error.message}`);
  }
}

/**
 * Select random peers for shard distribution
 * @param {Array<Object>} peers - Available peers
 * @param {number} count - Number of peers to select
 * @returns {Array<Object>} Selected peers
 */
function selectRandomPeers(peers, count) {
  if (peers.length <= count) {
    return [...peers]; // Return all peers if we don't have enough
  }
  
  const selectedPeers = [];
  const peersCopy = [...peers];
  
  // Randomly select peers
  for (let i = 0; i < count; i++) {
    const randomIndex = Math.floor(Math.random() * peersCopy.length);
    selectedPeers.push(peersCopy[randomIndex]);
    peersCopy.splice(randomIndex, 1);
  }
  
  return selectedPeers;
}

/**
 * Distribute a shard to the network
 * @param {string} shardId - Shard identifier
 * @param {Buffer} shardData - Shard data
 * @param {Object} merkleProof - Merkle proof for verification
 * @param {number} replicationFactor - Number of peers to replicate to
 * @returns {Promise<Object>} Distribution result
 */
async function distributeShard(shardId, shardData, merkleProof, replicationFactor = DEFAULT_REDUNDANCY) {
  // Check if peer manager is available
  if (!peerManager || typeof peerManager.getPeers !== 'function') {
    shardLogger.warn('Peer manager not available, skipping network distribution');
    return { 
      shardId, 
      success: false, 
      error: 'Peer manager not available' 
    };
  }
  
  // Get available peers
  const peers = peerManager.getPeers();
  
  if (!peers || peers.length === 0) {
    shardLogger.warn('No peers available for shard distribution');
    return { 
      shardId, 
      success: false, 
      error: 'No peers available' 
    };
  }
  
  // Select random peers for this shard
  const selectedPeers = selectRandomPeers(peers, replicationFactor);
  const peerResults = [];
  let successCount = 0;
  
  // Send shard to each selected peer
  for (const peer of selectedPeers) {
    try {
      const message = {
        type: 'store-shard',
        shardId,
        shardData: shardData.toString('base64'),
        merkleProof
      };
      
      const result = await peerManager.sendMessage(peer.id, message, SHARD_TIMEOUT);
      
      if (result.success) {
        successCount++;
      }
      
      peerResults.push({
        peerId: peer.id,
        success: result.success,
        error: result.error
      });
    } catch (error) {
      shardLogger.error('Failed to send shard to peer', { 
        shardId: shardId.substring(0, 10) + '...',
        peerId: peer.id,
        error: error.message
      });
      
      peerResults.push({
        peerId: peer.id,
        success: false,
        error: error.message
      });
    }
  }
  
  const success = successCount > 0;
  
  if (success) {
    shardLogger.info(`Distributed shard ${shardId.substring(0, 10)}... to ${successCount}/${selectedPeers.length} peers`);
  } else {
    shardLogger.warn(`Failed to distribute shard ${shardId.substring(0, 10)}... to any peers`);
  }
  
  return {
    shardId,
    success,
    distributedCount: successCount,
    totalPeers: selectedPeers.length,
    peerResults
  };
}

/**
 * Distribute multiple shards to the network
 * @param {Array<Object>} shards - Shard objects with id and data
 * @param {number} replicationFactor - Number of peers to replicate to
 * @returns {Promise<Array<Object>>} Results for each shard
 */
async function distributeShardsToNetwork(shards, replicationFactor = DEFAULT_REDUNDANCY) {
  const results = [];
  
  for (const shard of shards) {
    try {
      // Create Merkle proof for this shard
      // In a real implementation, this would be a proper proof
      const merkleProof = {
        index: shard.index,
        dataId: shard.dataId
      };
      
      // Distribute the shard
      const result = await distributeShard(
        shard.id, 
        shard.data, 
        merkleProof, 
        replicationFactor
      );
      
      results.push({
        shardId: shard.id,
        success: result.success,
        distributedCount: result.distributedCount
      });
    } catch (error) {
      shardLogger.error(`Failed to distribute shard ${shard.id}`, { 
        error: error.message 
      });
      
      results.push({
        shardId: shard.id,
        success: false,
        error: error.message
      });
    }
  }
  
  return results;
}

/**
 * Retrieve a shard from the network
 * @param {string} shardId - Shard identifier
 * @returns {Promise<Buffer|null>} Shard data or null if not found
 */
async function retrieveShard(shardId) {
  try {
    // First try to get locally
    let shardData = await getShardLocally(shardId);
    
    // If found locally, return it
    if (shardData) {
      return shardData;
    }
    
    // Otherwise, try to get from network
    shardLogger.debug(`Shard ${shardId.substring(0, 10)}... not found locally, trying network`);
    
    // Check if peer manager is available
    if (!peerManager || typeof peerManager.queryNetwork !== 'function') {
      shardLogger.warn(`Peer manager not available, cannot retrieve shard ${shardId.substring(0, 10)}...`);
      return null;
    }
    
    // Query the network for this shard
    const query = {
      type: 'get-shard',
      shardId
    };
    
    const networkResults = await peerManager.queryNetwork(query, MAX_RETRY_COUNT);
    
    // Find the first successful response
    const successResult = networkResults.find(result => 
      result.success && result.data && result.data.shardData
    );
    
    if (!successResult) {
      shardLogger.warn(`Shard ${shardId.substring(0, 10)}... not found in network`);
      return null;
    }
    
    // Convert base64 back to buffer
    shardData = Buffer.from(successResult.data.shardData, 'base64');
    
    // Store locally for future use
    await storeShardLocally(shardId, shardData);
    
    shardLogger.info(`Retrieved shard ${shardId.substring(0, 10)}... from network`);
    
    return shardData;
  } catch (error) {
    shardLogger.error(`Failed to retrieve shard ${shardId}`, { 
      error: error.message 
    });
    
    return null;
  }
}

/**
 * Fetch multiple shards from the network
 * @param {Array<string>} shardIds - Array of shard identifiers
 * @returns {Promise<Map<string, Buffer>>} Map of shardId to shard data
 */
async function fetchShardsFromNetwork(shardIds) {
  const shardMap = new Map();
  
  // Process in parallel with Promise.all
  await Promise.all(shardIds.map(async (shardId) => {
    try {
      const shardData = await retrieveShard(shardId);
      if (shardData) {
        shardMap.set(shardId, shardData);
      }
    } catch (error) {
      shardLogger.error(`Failed to fetch shard ${shardId}`, { 
        error: error.message 
      });
    }
  }));
  
  shardLogger.info(`Fetched ${shardMap.size}/${shardIds.length} shards from network`);
  
  return shardMap;
}

/**
 * Shard and distribute data across the network
 * @param {Buffer|string} data - Data to shard and distribute
 * @param {string} dataId - Unique identifier for this data
 * @param {Object} options - Sharding options
 * @param {number} options.shardSize - Size of each shard in bytes
 * @param {number} options.redundancy - Redundancy factor
 * @returns {Promise<Object>} Result of distribution
 */
export async function shardAndDistributeData(data, dataId, options = {}) {
  try {
    const dataBuffer = Buffer.isBuffer(data) ? data : Buffer.from(data);
    const shardSize = options.shardSize || DEFAULT_SHARD_SIZE;
    const redundancy = options.redundancy || DEFAULT_REDUNDANCY;
    const replicationFactor = options.replicationFactor || DEFAULT_REDUNDANCY;
    
    // Split data into shards
    const dataShards = shardData(dataBuffer, shardSize);
    
    // Generate redundant shards
    const redundantShards = generateRedundantShards(dataShards, redundancy);
    
    // Combine all shards
    const allShards = [...dataShards, ...redundantShards];
    
    // Generate Merkle tree for verification
    const merkleTree = generateMerkleTree(allShards);
    
    // Create shard objects with metadata
    const shardInfoList = [];
    
    // Add data shards
    for (let i = 0; i < dataShards.length; i++) {
      shardInfoList.push(createShard(dataShards[i], i, dataId, false));
    }
    
    // Add redundant shards
    for (let i = 0; i < redundantShards.length; i++) {
      shardInfoList.push(createShard(
        redundantShards[i], 
        dataShards.length + i, 
        dataId, 
        true
      ));
    }
    
    // Store shards locally first
    for (const shardInfo of shardInfoList) {
      await storeShardLocally(shardInfo.id, shardInfo.data);
    }
    
    // Distribute to network
    const distributionResults = await distributeShardsToNetwork(
      shardInfoList,
      replicationFactor
    );
    
    // Store metadata for retrieval
    const metadata = {
      dataId,
      totalSize: dataBuffer.length,
      shardSize,
      totalShards: dataShards.length,
      redundantShards: redundantShards.length,
      merkleRoot: merkleTree.rootHash,
      timestamp: Date.now(),
      shards: shardInfoList.map(info => ({
        id: info.id,
        index: info.index,
        isRedundant: info.isRedundant
      }))
    };
    
    // Store metadata in DHT
    await peerManager.storeDataInDHT(`metadata:${dataId}`, JSON.stringify(metadata), {
      replicationFactor,
      metadata: {
        type: 'metadata',
        dataId
      }
    });
    
    shardLogger.info(`Sharded and distributed data ${dataId}`, {
      dataSize: dataBuffer.length,
      shardCount: allShards.length,
      redundancy
    });
    
    return {
      success: true,
      dataId,
      merkleRoot: merkleTree.rootHash,
      shardCount: allShards.length,
      metadata
    };
  } catch (error) {
    shardLogger.error('Failed to shard and distribute data', { 
      error: error.message 
    });
    
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Retrieve and reconstruct data from shards
 * @param {string} dataId - ID of the data to retrieve
 * @returns {Promise<Buffer|null>} Reconstructed data or null if not retrievable
 */
export async function retrieveAndReconstructData(dataId) {
  try {
    // Retrieve metadata
    const metadataKey = `metadata:${dataId}`;
    const metadataStr = await peerManager.retrieveDataFromDHT(metadataKey);
    
    if (!metadataStr) {
      throw new Error(`Metadata for ${dataId} not found`);
    }
    
    const metadata = JSON.parse(metadataStr);
    
    // Extract shard IDs
    const shardIds = metadata.shards.map(shard => shard.id);
    
    // Fetch shards from network
    const shards = await fetchShardsFromNetwork(shardIds);
    
    // Check if we have enough shards to reconstruct the data
    const dataShardCount = metadata.totalShards;
    const dataShards = [];
    
    // First try to get all data shards
    for (let i = 0; i < dataShardCount; i++) {
      const shardInfo = metadata.shards[i];
      const shardData = shards.get(shardInfo.id);
      
      if (shardData) {
        dataShards[i] = shardData;
      }
    }
    
    // If any data shards are missing, try to reconstruct using redundant shards
    if (dataShards.some(shard => !shard)) {
      shardLogger.warn(`Missing some data shards for ${dataId}, attempting reconstruction`);
      
      // Count missing data shards
      const missingCount = dataShards.filter(s => !s).length;
      
      // If we're missing more data shards than we have redundant shards, we can't reconstruct
      if (missingCount > metadata.redundantShards) {
        throw new Error(`Cannot reconstruct data: missing ${missingCount} shards with only ${metadata.redundantShards} redundant shards`);
      }
      
      // Implement shard reconstruction using redundant shards
      // In a full implementation, this would use Reed-Solomon or similar
      // For this simplified version, we'll implement a basic XOR-based reconstruction
      
      // Get all available shards (data and redundant)
      const availableShards = [];
      for (let i = 0; i < metadata.shards.length; i++) {
        const shardInfo = metadata.shards[i];
        const shardData = shards.get(shardInfo.id);
        
        if (shardData) {
          availableShards.push({
            data: shardData,
            index: shardInfo.index,
            isRedundant: shardInfo.isRedundant
          });
        }
      }
      
      // For each missing data shard, try to reconstruct
      for (let i = 0; i < dataShardCount; i++) {
        if (!dataShards[i]) {
          // Find a redundant shard to use for reconstruction
          const redundantShard = availableShards.find(s => s.isRedundant);
          
          if (!redundantShard) {
            throw new Error('No redundant shards available for reconstruction');
          }
          
          // Remove this redundant shard from available shards
          const redundantIndex = availableShards.findIndex(s => s === redundantShard);
          availableShards.splice(redundantIndex, 1);
          
          // Create a buffer for the reconstructed shard
          const reconstructedShard = Buffer.alloc(metadata.shardSize);
          
          // Copy the redundant shard as a starting point
          redundantShard.data.copy(reconstructedShard);
          
          // XOR with all other available data shards
          for (const shard of availableShards) {
            if (!shard.isRedundant) {
              for (let j = 0; j < reconstructedShard.length; j++) {
                if (j < shard.data.length) {
                  reconstructedShard[j] ^= shard.data[j];
                }
              }
            }
          }
          
          // Use the reconstructed shard
          dataShards[i] = reconstructedShard;
          
          shardLogger.info(`Reconstructed shard index ${i} for ${dataId}`);
        }
      }
    }
    
    // Combine shards to reconstruct the data
    const reconstructedData = Buffer.concat(dataShards);
    
    // Verify size matches metadata
    if (reconstructedData.length !== metadata.totalSize) {
      throw new Error(`Reconstructed data size mismatch: expected ${metadata.totalSize}, got ${reconstructedData.length}`);
    }
    
    shardLogger.info(`Successfully retrieved and reconstructed data ${dataId}`);
    
    return reconstructedData;
  } catch (error) {
    shardLogger.error(`Failed to retrieve data ${dataId}`, { 
      error: error.message 
    });
    
    return null;
  }
}

/**
 * Monitor shard health and repair as needed
 * @param {string} dataId - ID of data to check
 * @returns {Promise<Object>} Health check results
 */
export async function monitorAndRepairShards(dataId) {
  try {
    // Retrieve metadata
    const metadataKey = `metadata:${dataId}`;
    const metadataStr = await peerManager.retrieveDataFromDHT(metadataKey);
    
    if (!metadataStr) {
      throw new Error(`Metadata for ${dataId} not found`);
    }
    
    const metadata = JSON.parse(metadataStr);
    
    // Check availability of each shard
    const shardAvailability = [];
    const missingShards = [];
    
    for (const shardInfo of metadata.shards) {
      const dhtKey = `shard:${shardInfo.id}`;
      const availability = await peerManager.checkDataAvailability(dhtKey);
      
      shardAvailability.push({
        shardId: shardInfo.id,
        available: availability.available,
        replicaCount: availability.replicaCount
      });
      
      if (!availability.available) {
        missingShards.push(shardInfo);
      }
    }
    
    // If any shards are missing, try to repair
    let repairResults = null;
    if (missingShards.length > 0) {
      shardLogger.warn(`Found ${missingShards.length} missing shards for ${dataId}, attempting repair`);
      
      repairResults = await repairMissingShards(dataId, missingShards, metadata);
    }
    
    return {
      dataId,
      health: missingShards.length === 0 ? 'healthy' : (repairResults?.success ? 'repaired' : 'degraded'),
      shardCount: metadata.shards.length,
      missingCount: missingShards.length,
      availability: shardAvailability,
      repairResults
    };
  } catch (error) {
    shardLogger.error(`Failed to check shard health for ${dataId}`, { 
      error: error.message 
    });
    
    return {
      dataId,
      health: 'unknown',
      error: error.message
    };
  }
}

/**
 * Repair missing shards
 * @param {string} dataId - ID of the data
 * @param {Array<Object>} missingShards - Missing shard info
 * @param {Object} metadata - Data metadata
 * @returns {Promise<Object>} Repair results
 */
async function repairMissingShards(dataId, missingShards, metadata) {
  try {
    // First, retrieve all available shards
    const availableShardIds = metadata.shards
      .filter(shard => !missingShards.some(missing => missing.id === shard.id))
      .map(shard => shard.id);
    
    const availableShards = await fetchShardsFromNetwork(availableShardIds);
    
    // Check if we have enough shards to reconstruct
    if (availableShards.size < metadata.totalShards) {
      return {
        success: false,
        reason: 'Not enough shards available for reconstruction',
        availableCount: availableShards.size,
        requiredCount: metadata.totalShards
      };
    }
    
    // Reconstruct missing shards
    const repairedShards = [];
    
    for (const missingShard of missingShards) {
      // Prepare collection of available data shards
      const dataShardBuffers = [];
      for (let i = 0; i < metadata.totalShards; i++) {
        const shardInfo = metadata.shards[i];
        const shardData = availableShards.get(shardInfo.id);
        if (shardData) {
          dataShardBuffers.push(shardData);
        }
      }
      
      // For data shards, we need to use the actual recovery algorithm
      // For redundant shards, we can regenerate them
      let repairedShardData;
      
      if (missingShard.isRedundant) {
        // Regenerate redundant shard using XOR
        repairedShardData = Buffer.alloc(metadata.shardSize);
        for (const dataShard of dataShardBuffers) {
          for (let i = 0; i < repairedShardData.length; i++) {
            if (i < dataShard.length) {
              repairedShardData[i] ^= dataShard[i];
            }
          }
        }
      } else {
        // For data shards, we need a more complex reconstruction
        // This would use Reed-Solomon or similar in a real implementation
        // For this demo, we'll use a simplified approach assuming we have at least one redundant shard
        
        // Find a redundant shard
        const redundantShardInfo = metadata.shards.find(s => s.isRedundant);
        if (!redundantShardInfo) {
          return {
            success: false,
            reason: 'No redundant shards available for data shard reconstruction'
          };
        }
        
        const redundantShardData = availableShards.get(redundantShardInfo.id);
        if (!redundantShardData) {
          return {
            success: false,
            reason: 'Redundant shard not available despite being in metadata'
          };
        }
        
        // Start with the redundant shard
        repairedShardData = Buffer.from(redundantShardData);
        
        // XOR with all other data shards except the missing one
        for (let i = 0; i < metadata.totalShards; i++) {
          if (i !== missingShard.index) {
            const shardInfo = metadata.shards[i];
            const shardData = availableShards.get(shardInfo.id);
            
            if (shardData) {
              for (let j = 0; j < repairedShardData.length; j++) {
                if (j < shardData.length) {
                  repairedShardData[j] ^= shardData[j];
                }
              }
            }
          }
        }
      }
      
      // Store the repaired shard locally
      await storeShardLocally(missingShard.id, repairedShardData);
      
      // Distribute to network
      await distributeShard(
        missingShard.id, 
        repairedShardData,
        { index: missingShard.index, dataId },
        DEFAULT_REDUNDANCY
      );
      
      repairedShards.push(missingShard.id);
    }
    
    shardLogger.info(`Repaired ${repairedShards.length} shards for ${dataId}`);
    
    return {
      success: true,
      repairedCount: repairedShards.length,
      repairedShards
    };
  } catch (error) {
    shardLogger.error(`Failed to repair shards for ${dataId}`, { 
      error: error.message 
    });
    
    return {
      success: false,
      reason: error.message
    };
  }
}

// Initialize
ensureShardsDir().catch(error => {
  shardLogger.error('Failed to ensure shards directory', { error: error.message });
});

export default {
  shardAndDistributeData,
  retrieveAndReconstructData,
  monitorAndRepairShards,
  createShard,          // Export additional functions for flexibility
  distributeShard,
  retrieveShard
};